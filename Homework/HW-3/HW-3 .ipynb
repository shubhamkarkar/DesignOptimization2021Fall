{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1f19d19",
   "metadata": {},
   "source": [
    "Problem 1 (50 points)\n",
    "Vapor-liquid equilibria data are correlated using two adjustable parameters $A_{12}$ and $A_{21}$ per binary mixture. For low pressures, the equilibrium relation can be formulated as:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p = &amp; x_1\\exp\\left(A_{12}\\left(\\frac{A_{21}x_2}{A_{12}x_1+A_{21}x_2}\\right)^2\\right)p_{water}^{sat}\\\\\n",
    "&amp; + x_2\\exp\\left(A_{21}\\left(\\frac{A_{12}x_1}{A_{12}x_1+A_{21}x_2}\\right)^2\\right)p_{1,4 dioxane}^{sat}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "Here the saturation pressures are given by the Antoine equation\n",
    "\n",
    "$$\n",
    "\\log_{10}(p^{sat}) = a_1 - \\frac{a_2}{T + a_3},\n",
    "$$\n",
    "where $T = 20$($^{\\circ}{\\rm C}$) and $a_{1,2,3}$ for a water - 1,4 dioxane system is given below.\n",
    "\n",
    "$a_1$\t$a_2$\t$a_3$\n",
    "Water\t8.07131\t1730.63\t233.426\n",
    "1,4 dioxane\t7.43155\t1554.679\t240.337\n",
    "The following table lists the measured data. Recall that in a binary system $x_1 + x_2 = 1$.\n",
    "\n",
    "$x_1$\t0.0\t0.1\t0.2\t0.3\t0.4\t0.5\t0.6\t0.7\t0.8\t0.9\t1.0\n",
    "$p$\t28.1\t34.4\t36.7\t36.9\t36.8\t36.7\t36.5\t35.4\t32.9\t27.7\t17.5\n",
    "Estimate $A_{12}$ and $A_{21}$ using data from the above table:\n",
    "\n",
    "Formulate the least square problem;\n",
    "Since the model is nonlinear, the problem does not have an analytical solution. Therefore, solve it using the gradient descent or Newton's method implemented in HW1;\n",
    "Compare your optimized model with the data. Does your model fit well with the data?\n",
    "Problem 2 (50 points)\n",
    "Solve the following problem using Bayesian Optimization:$$\n",
    "    \\min_{x_1, x_2} \\quad \\left(4-2.1x_1^2 + \\frac{x_1^4}{3}\\right)x_1^2 + x_1x_2 + \\left(-4 + 4x_2^2\\right)x_2^2,\n",
    "$$for $x_1 \\in [-3,3]$ and $x_2 \\in [-2,2]$. A tutorial on Bayesian Optimization can be found here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a9124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple example of using PyTorch for gradient descent\n",
    "\n",
    "import torch as t\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Define a variable, make sure requires_grad=True so that PyTorch can take gradient with respect to this variable\n",
    "x = Variable(t.tensor([1.0, 0.0]), requires_grad=True)\n",
    "\n",
    "# Define a loss\n",
    "loss = (x[0] - 1)**2 + (x[1] - 2)**2\n",
    "\n",
    "# Take gradient\n",
    "loss.backward()\n",
    "\n",
    "# Check the gradient. numpy() turns the variable from a PyTorch tensor to a numpy array.\n",
    "x.grad.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825be441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine the gradient at a different x.\n",
    "x.data = t.tensor([2.0, 1.0])\n",
    "loss = (x[0] - 1)**2 + (x[1] - 2)**2\n",
    "loss.backward()\n",
    "x.grad.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c941d77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine the gradient at a different x.\n",
    "x.data = t.tensor([2.0, 1.0])\n",
    "loss = (x[0] - 1)**2 + (x[1] - 2)**2\n",
    "loss.backward()\n",
    "x.grad.numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
